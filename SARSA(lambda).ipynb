{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "337c36fb",
   "metadata": {},
   "source": [
    "## Importing the needed libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52745a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5bf753",
   "metadata": {},
   "source": [
    "### NOTE: After running the function \"maze_creator\", one needs to check if the goal is reachable at all (by looking at the generated plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5911cb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maze Data:\n",
      "{'maze': array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
      "       [0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 1, 0, 0, 1, 0]]), 'initial_state': (2, 0), 'goal_state': (0, 8), 'obstacles': [(4, 3), (5, 4), (5, 7), (2, 6), (1, 6), (3, 2), (2, 8)], 'rows': 6, 'cols': 9, 'actions': ['Right', 'Left', 'Up', 'Down']}\n"
     ]
    }
   ],
   "source": [
    "def maze_creator(rows, cols, num_obstacles, initial_state, goal_state, actions_list):\n",
    "    \"\"\"\n",
    "    Create and visualize a maze, and return a structured representation of it.\n",
    "\n",
    "    Parameters:\n",
    "        rows (int): Number of rows in the maze.\n",
    "        cols (int): Number of columns in the maze.\n",
    "        num_obstacles (int): Number of obstacles to place in the maze.\n",
    "        initial_state (tuple): Coordinates of the initial state (row, col).\n",
    "        goal_state (tuple): Coordinates of the goal state (row, col).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the maze grid and its metadata.\n",
    "    \"\"\"\n",
    "    random.seed(2024)\n",
    "    \n",
    "    # Create a blank maze (0 for open spaces)\n",
    "    maze = np.zeros((rows, cols), dtype=int)\n",
    "\n",
    "    # Place the initial and goal states\n",
    "    maze[initial_state] = 0  \n",
    "    maze[goal_state] = 0  \n",
    "\n",
    "    # Randomly place obstacles\n",
    "    obstacle_positions = set()\n",
    "    while len(obstacle_positions) < num_obstacles:\n",
    "        obstacle = (random.randint(0, rows - 1), random.randint(0, cols - 1))\n",
    "        if obstacle != initial_state and obstacle != goal_state:\n",
    "            obstacle_positions.add(obstacle)\n",
    "\n",
    "    for obs in obstacle_positions:\n",
    "        maze[obs] = 1  # Mark obstacles as 1\n",
    "\n",
    "    # Visualize the maze\n",
    "    plt.figure(figsize=(cols, rows))\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if (i, j) == initial_state:\n",
    "                color = 'green'\n",
    "            elif (i, j) == goal_state:\n",
    "                color = 'red'\n",
    "            elif maze[i, j] == 1:\n",
    "                color = 'black'  \n",
    "            else:\n",
    "                color = 'white' \n",
    "\n",
    "            # Draw each cell as a square\n",
    "            plt.gca().add_patch(plt.Rectangle((j, rows - 1 - i), 1, 1, edgecolor='black', facecolor=color))\n",
    "\n",
    "    # Set the plot limits and aspect ratio\n",
    "    plt.xlim(0, cols)\n",
    "    plt.ylim(0, rows)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Maze with Initial and Goal States\")\n",
    "    plt.show()\n",
    "\n",
    "    # Return the maze data\n",
    "    return {\n",
    "        \"maze\": maze,\n",
    "        \"initial_state\": initial_state,\n",
    "        \"goal_state\": goal_state,\n",
    "        \"obstacles\": list(obstacle_positions),\n",
    "        \"rows\": rows,\n",
    "        \"cols\": cols,\n",
    "        \"actions\": actions_list\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage\n",
    "maze_data = maze_creator(\n",
    "    rows=6,\n",
    "    cols=9,\n",
    "    num_obstacles=7,\n",
    "    initial_state=(2, 0),\n",
    "    goal_state=(0, 8),\n",
    "    actions_list = [\"Right\", \"Left\", \"Up\", \"Down\"]\n",
    ")\n",
    "\n",
    "# Print the maze data\n",
    "print(\"Maze Data:\")\n",
    "print(maze_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c1ac2d",
   "metadata": {},
   "source": [
    "## Action performer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3be4411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action: Right, New State: 34\n",
      "Action: Left, New State: 32\n",
      "Action: Up, New State: 33\n",
      "Action: Down, New State: 42\n"
     ]
    }
   ],
   "source": [
    "def action_performer(state, action, maze_data):\n",
    "    \"\"\"\n",
    "    Determine the resulting state based on the current state, action, and maze data.\n",
    "\n",
    "    Parameters:\n",
    "        state (int): The current state of the agent (0-indexed).\n",
    "        action (str): The action to perform ('Right', 'Left', 'Up', 'Down').\n",
    "        maze_data (dict): The data describing the maze created by maze_creator.\n",
    "\n",
    "    Returns:\n",
    "        int: The resulting state after performing the action.\n",
    "    \"\"\"\n",
    "    rows, cols = maze_data['rows'], maze_data['cols']\n",
    "    obstacles = set(maze_data['obstacles'])\n",
    "\n",
    "    # Convert the 0-indexed state into row and column\n",
    "    row, col = divmod(state, cols)\n",
    "\n",
    "    # Determine the new position based on the action\n",
    "    if action == \"Right\":\n",
    "        new_row, new_col = row, col + 1\n",
    "    elif action == \"Left\":\n",
    "        new_row, new_col = row, col - 1\n",
    "    elif action == \"Up\":\n",
    "        new_row, new_col = row - 1, col\n",
    "    elif action == \"Down\":\n",
    "        new_row, new_col = row + 1, col\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid action: {action}\")\n",
    "\n",
    "    # Check if the new position is within the maze bounds\n",
    "    if 0 <= new_row < rows and 0 <= new_col < cols:\n",
    "        # Check if the new position is not an obstacle\n",
    "        if (new_row, new_col) not in obstacles:\n",
    "            # Convert the position back to 0-indexed state\n",
    "            return new_row * cols + new_col\n",
    "\n",
    "    # If the move is invalid (out of bounds or obstacle), return the original state\n",
    "    return state\n",
    "\n",
    "current_state = 33  # State (1, 0) in a 0-indexed maze\n",
    "actions_list = [\"Right\", \"Left\", \"Up\", \"Down\"]\n",
    "\n",
    "# Apply actions and print the results\n",
    "for action in actions_list:\n",
    "    new_state = action_performer(current_state, action, maze_data)\n",
    "    print(f\"Action: {action}, New State: {new_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f8f2cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_start(maze_data):\n",
    "    rows = maze_data[\"rows\"]\n",
    "    cols = maze_data[\"cols\"]\n",
    "    actions = maze_data[\"actions\"]\n",
    "    obstacles = maze_data[\"obstacles\"]\n",
    "    goal_state = maze_data[\"goal_state\"]\n",
    "    \n",
    "    while True:\n",
    "        # Randomly pick a state\n",
    "        state = random.randint(0, rows * cols - 1)\n",
    "        row, col = divmod(state, cols)  # Convert state to (row, col)\n",
    "        \n",
    "        # Skip if the state is the goal state or an obstacle\n",
    "        if (row, col) == goal_state or (row, col) in obstacles:\n",
    "            continue\n",
    "        \n",
    "        break\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c520567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_policy(maze_data, state_action_values, policy, state, epsilon):\n",
    "    \n",
    "    action_space = len(maze_data['actions'])\n",
    "    epsilon_value = epsilon/action_space\n",
    "    \n",
    "    max_value = max(state_action_values[state].values())\n",
    "    max_actions = [act for act, val in state_action_values[state].items() if val == max_value]\n",
    "                \n",
    "    num_max_actions = len(max_actions)\n",
    "    if num_max_actions == action_space:\n",
    "        return\n",
    "    \n",
    "    j = 0\n",
    "    for act in policy[state]:\n",
    "        if act in max_actions:\n",
    "            policy[state][act] = 1 / num_max_actions + epsilon_value # Equal probability for tied actions\n",
    "            if j == 0:\n",
    "                policy[state][act] -= epsilon\n",
    "                j = 1\n",
    "        else:\n",
    "            policy[state][act] = epsilon_value\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33eaae02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def action_picker(maze_data, policy, state):\n",
    "    actions = maze_data[\"actions\"]\n",
    "    action_probabilities = list(policy[state].values())\n",
    "    next_action = random.choices(actions, weights=action_probabilities, k=1)[0]\n",
    "    return next_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b62a90",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 85\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m policy, state_action_values\n\u001b[1;32m---> 85\u001b[0m policy_1, state_action_values_1 \u001b[38;5;241m=\u001b[39m \u001b[43msarsa_lambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaze_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 67\u001b[0m, in \u001b[0;36msarsa_lambda\u001b[1;34m(maze_data, lambda_0, alpha_0, gamma_0, epsilon)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[0;32m     66\u001b[0m         z[s][a] \u001b[38;5;241m=\u001b[39m gamma_0\u001b[38;5;241m*\u001b[39mlambda_0\u001b[38;5;241m*\u001b[39mz[s][a]\n\u001b[1;32m---> 67\u001b[0m         state_action_values[s][a] \u001b[38;5;241m=\u001b[39m state_action_values[s][a] \u001b[38;5;241m+\u001b[39m alpha_0\u001b[38;5;241m*\u001b[39mdelta\u001b[38;5;241m*\u001b[39m\u001b[43mz\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m[a]\n\u001b[0;32m     68\u001b[0m         update_policy(maze_data, state_action_values, policy, s, epsilon)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mdivmod\u001b[39m(new_state, cols) \u001b[38;5;241m==\u001b[39m goal_state:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def sarsa_lambda(maze_data, lambda_0, alpha_0, gamma_0, epsilon):\n",
    "    \n",
    "    rows = maze_data[\"rows\"]\n",
    "    cols = maze_data[\"cols\"]\n",
    "    actions = maze_data[\"actions\"]\n",
    "    obstacles = maze_data[\"obstacles\"]\n",
    "    goal_state = maze_data[\"goal_state\"]\n",
    "    \n",
    "    # Initialize\n",
    "    # Take equal probabilities for each action\n",
    "    # Take all state action values to be 0 initially\n",
    "    initial_action_probabilties = 1/len(actions)\n",
    "    \n",
    "    policy = {}\n",
    "    state_action_values = {}\n",
    "    state_action_visits = {}\n",
    "    \n",
    "    for i in range(rows*cols):\n",
    "        temp_dict_policy = {}\n",
    "        temp_dict_action_values = {}\n",
    "        temp_dict_action_visits = {}\n",
    "        \n",
    "        for j in actions:\n",
    "            temp_dict_policy[j] = initial_action_probabilties\n",
    "            temp_dict_action_values[j] = 0\n",
    "            temp_dict_action_visits[j] = 0\n",
    "        \n",
    "        policy[i] = temp_dict_policy\n",
    "        state_action_values[i] = temp_dict_action_values\n",
    "        state_action_visits[i] = temp_dict_action_visits\n",
    "        \n",
    "        \n",
    "    k = 0\n",
    "    # Episodes\n",
    "    while True:\n",
    "        k = k+1\n",
    "        state = generate_random_start(maze_data)\n",
    "        action = action_picker(maze_data, policy, state)\n",
    "        \n",
    "        #Eligibility traces\n",
    "        z = {}\n",
    "        for i in range(rows*cols):\n",
    "            temp_z = {}\n",
    "            for j in actions:\n",
    "                temp_z[j] = 0\n",
    "            z[i] = temp_z\n",
    "        \n",
    "        # Until Terminal\n",
    "        l = 0\n",
    "        while True:\n",
    "            l = l + 1\n",
    "            new_state = action_performer(state, action, maze_data)\n",
    "            new_action = action_picker(maze_data, policy, new_state)\n",
    "            \n",
    "            if divmod(new_state, cols) == goal_state:\n",
    "                R = 1\n",
    "            else:\n",
    "                R = 0\n",
    "            \n",
    "            # Delta\n",
    "            old = state_action_values[state][action]\n",
    "            delta = R + gamma_0*state_action_values[new_state][new_action] - old\n",
    "            z[state][action] +=1\n",
    "            for s in range(rows*cols):\n",
    "                for a in actions:\n",
    "                    z[s][a] = gamma_0*lambda_0*z[s][a]\n",
    "                    state_action_values[s][a] = state_action_values[s][a] + alpha_0*delta*z[s][a]\n",
    "                    update_policy(maze_data, state_action_values, policy, s, epsilon)\n",
    "            \n",
    "            if divmod(new_state, cols) == goal_state:\n",
    "                break\n",
    "            \n",
    "            state = new_state\n",
    "            action = new_action\n",
    "            \n",
    "            if l > 10000:\n",
    "                break\n",
    "        \n",
    "        \n",
    "        if k > 10000:\n",
    "            break\n",
    "            \n",
    "    return policy, state_action_values\n",
    "\n",
    "policy_1, state_action_values_1 = sarsa_lambda(maze_data, 0, 0.5, 0.9, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7423ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(policy, maze_data):\n",
    "    rows = maze_data[\"rows\"]\n",
    "    cols = maze_data[\"cols\"]\n",
    "    obstacles = maze_data[\"obstacles\"]\n",
    "    goal_state = maze_data[\"goal_state\"]  # Now as (row, col)\n",
    "    initial_state = maze_data[\"initial_state\"]  # Now as (row, col)\n",
    "\n",
    "    # Create a grid\n",
    "    fig, ax = plt.subplots(figsize=(cols, rows))\n",
    "    ax.set_xlim(-0.5, cols - 0.5)\n",
    "    ax.set_ylim(-0.5, rows - 0.5)\n",
    "    ax.set_xticks(np.arange(-0.5, cols, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-0.5, rows, 1), minor=True)\n",
    "    ax.grid(which=\"minor\", color=\"black\", linestyle=\"-\", linewidth=0.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Draw obstacles\n",
    "    for obstacle in obstacles:\n",
    "        ax.add_patch(plt.Rectangle((obstacle[1] - 0.5, rows - obstacle[0] - 1.5), 1, 1, color=\"black\"))\n",
    "    \n",
    "    # Mark the initial state in green\n",
    "    ax.add_patch(plt.Rectangle((initial_state[1] - 0.5, rows - initial_state[0] - 1.5), 1, 1, color=\"green\"))\n",
    "    \n",
    "    # Mark the goal state in red\n",
    "    ax.add_patch(plt.Rectangle((goal_state[1] - 0.5, rows - goal_state[0] - 1.5), 1, 1, color=\"red\"))\n",
    "\n",
    "    # Define arrow directions\n",
    "    arrow_mapping = {\n",
    "        \"Right\": (0.4, 0),  # Move right\n",
    "        \"Left\": (-0.4, 0),  # Move left\n",
    "        \"Up\": (0, 0.4),     # Move up\n",
    "        \"Down\": (0, -0.4),  # Move down\n",
    "    }\n",
    "\n",
    "    # Add arrows for each cell\n",
    "    for state, actions in policy.items():\n",
    "        row, col = divmod(state, cols)\n",
    "        cell = (row, col)  # Convert state to tuple for comparison\n",
    "        if cell in obstacles or cell == goal_state:\n",
    "            continue  # Skip obstacles, goal state, and initial state\n",
    "\n",
    "        # Find the action(s) with max probability\n",
    "        max_prob = max(actions.values())\n",
    "        max_actions = [action for action, prob in actions.items() if prob == max_prob]\n",
    "\n",
    "        for action in max_actions:\n",
    "            dx, dy = arrow_mapping[action]\n",
    "            ax.arrow(\n",
    "                col, rows - row - 1, dx, dy,\n",
    "                head_width=0.2, head_length=0.2, fc=\"blue\", ec=\"blue\"\n",
    "            )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_policy(policy_1, maze_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4290e03a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
